[Up](../index.md)

# Tensorflow

## 입문자들에게 알립니다.

단편적인 기술 블로그의 글은 검색하여 찾아 보기 쉬운 잇점이 있으며, 중급 이상의 엔지니어에게 도움이 됩니다. **새로운 분야를 시작하려는 입문자들에게 경고 합니다**. 블로그는 단편적인 내용을 담고 있으며, 체계적이지도 않으며 학습 순서에 따라 기술하지도 않습니다. 입문자가 블로그를 통해 공부를 하면 빠져나오기 힘든 함정에 빠질 수 있습니다. 반드시! 체계적인 전문서적이나 강의를 통해 학습하시기 바랍니다. 이 블로그에서 링크들은 웹사이트, 블로그, 서적, 논문임을 표시하고 있으므로 해당 링크를 클릭하기 전에 확인하시기 바랍니다.

딥러닝 이론 과정을 거치셨습니까? 텐서플로우는 모델을 구현하는 도구일 뿐이며 텐서플로우 API만을 익혀서 사용하기 어렵습니다. 먼저 이론 과정을 거치셔야 합니다. [[Bishop 2007]](https://www.springer.com/gp/book/9780387310732), [[Goodfellow 2016]](http://www.deeplearningbook.org/), [[오일석 2017]](http://www.hanbit.co.kr/store/books/look.php?p_code=B4606522972)이나 이에 준하는 수준의 이론 과정을 먼저 거치기 바랍니다.

****

## tf

### tf.get_variable

이러한 매개 변수를 사용하여 기존 변수를 가져 오거나 새 변수를 만듭니다.

### tf.identity

같은 모양과 내용을 가진 텐서를 입력으로 되돌립니다.

### tf.pad

텐서를 패딩합니다.

### tf.reduce_mean

텐서의 차원에서 요소의 평균을 계산합니다. 축에 주어진 차원을 따라 `input_tensor`를 줄입니다. `keepdims`가 `true`가 아닌 한, 텐서의 랭크는 축의 각 엔트리마다 1 씩 감소합니다. `keepdims`가 true이면 축소 된 차원은 길이가 1로 유지됩니다. 축에 항목이 없으면 모든 치수가 축소되고 단일 요소가있는 텐서가 반환됩니다.

### tf.transpose

입력된 텐서에 대해 전치(transpose)를 합니다.

### tf.variable_scope

변수 (계층)를 생성하는 op를 정의하기 위한 컨텍스트 관리자. 이 컨텍스트 관리자는 (선택적) 값이 동일한 그래프에서 왔는지 확인하고 그래프가 기본 그래프인지 확인하고 이름 범위와 변수 범위를 푸시합니다. ``name_or_scope``이 ``None``이 아니면 그대로 사용됩니다. ``name_or_scope``이 ``None``이면 ``default_name``이 사용됩니다. 이 경우 이전에 같은 이름으로 동일한 이름이 사용 된 경우 ``_N``을 추가하여 고유하게 만듭니다. 변수 범위를 사용하면 실수로 생성하거나 공유하지 않는 체크를 제공하면서 새 변수를 만들고 이미 작성된 변수를 공유 할 수 있습니다. 자세한 내용은 변수 범위 사용법을 참조하십시오. 여기서 몇 가지 기본 예제만 제시합니다.

---

##tf.layers

### tf.layers.dense

조밀하게 연결된 레이어의 기능적 인터페이스. 이 계층은 다음 연산을 구현합니다: `outputs = activation(inputs.kernel + bias)`. `activation은 activation` 인수로 전달된 활성화 함수입니다 (`None`이 아니면). `kernel`은 계층에 의해 만들어진 가중치 행렬이고 `bias`는 생성 된 바이어스 벡터입니다. (`use_bias`가 `True`인 경우에만).

---

## tf.contrib

### tf.contrib.layers.flatten

`batch_size`를 유지하면서 입력을 평평하게합니다. 첫 번째 차원이 일괄 처리를 나타내는 것으로 가정합니다.



