\documentclass[11pt, a4paper, oneside]{article}

\usepackage{color}
\usepackage{tikz}
\usepackage{showframe}
\usepackage{blindtext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{calc}  
\usepackage{enumitem} 
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{setspace}
\usepackage{glossaries}
\usepackage{latexsym}

\tikzset{
    vertex/.style = {
        circle,
        fill = black,
        outer sep = 2pt,
        inner sep = 1pt,
    }
}

\SetLabelAlign{parright}{\parbox[t]{\labelwidth}{\raggedleft#1}}
\setstretch{0.5}

\DeclareMathOperator*{\argmin}{argmin}

\begin{document}

\title{}
\author{}
\date{}

%Dataset
%name: LS3D-W.
%download: https://www.adrianbulat.com/face-alignment/

\part*{Studies dependency}.

\section*{Face alignment 2D}

Cao, X., Wei, Y., Wen, F., Sun, J.: Face alignment by explicit shape regression. In: CVPR. (2012)

Xiong, X., De la Torre, F.: Supervised descent method and its applications to face alignment. In: CVPR. (2013) 532–539

Jourabloo, A., Liu, X.: Pose-invariant 3d face alignment. In: CVPR. (2015) 3694–3702

Zhu, S., Li, C., Change Loy, C., Tang, X.: Face alignment by coarse-to-fine shape searching. In: CVPR. (2015) 4998–5006

Bulat, A., Tzimiropoulos, G.: Convolutional aggregation of local evidence for large pose face alignment. In: BMVC. (2016)

\section*{Face alignment 3D}

Bulat, A.,Tzimiropoulos, G.: Two-stage Convolutional Part Heatmap Regression for the 1st 3D Face Alignment in the Wild (3DFAW) Challenge. ???? (2016)


\part*{Bulat 2017 Face Alignment}

\noindent
Normalized Mean Error:

\begin{equation}
\text{NME}
= \frac{1}{N} \sum_{k=1}^N \frac{\| \mathbf{x}_k - \mathbf{y}_k \|^2}{d}
\tag{}
\end{equation}

\begin{description}[labelwidth=\widthof{\bfseries 123456789012345},align=parright]
	\item[Input variable: ]	$d = \sqrt{w_{ \mathit{bbox}} * h_{\mathit{bbox}} }$
	\item[$\mathit{bbox}:$] bounding box.
\end{description}

\bigskip

\part*{Bulat 2016 Two stage 3D pose}

\begin{equation}
l_2 = \frac{1}{N} \sum_{n=1}^N (\tilde{z}_n - z_n) _2
\tag{}
\end{equation}

\bigskip

\noindent
Ground Truth Error(GTE):

\begin{equation}
E( \mathbf{X}, \mathbf{Y})
= \frac{1}{N} \sum_{n=1}^N \frac{\| \mathbf{X}_n - \mathbf{Y}_n \|_2}{d_i}
\tag{}
\end{equation}

\begin{description}[labelwidth=\widthof{\bfseries 123456789012345},align=parright]
	\item[$\mathbf{X}$:] Predicted set of points.
	\item[$\mathbf{Y}$:] Corresponding ground truth.
	\item[$d_i$:] Interocular distance for the $i$th image.
\end{description}

\bigskip

\noindent
Cross View Ground Truth Consistency Error(CVGTCE):
\begin{equation}
E_{vc}( \mathbf{X}, \mathbf{Y}, T )
=\frac{1}{N} \sum_{n=1}^1 \frac{\| s\mathbf{Rx}_n - \mathbf{y}_n \|_2}{d_i}
\tag{}
\end{equation}

\begin{equation}
P = \{ s, \mathbf{R}, \mathbf{t} \}
\tag{}
\end{equation}

\begin{equation}
\{ s, \mathbf{R}, \mathbf{t} \}
= \argmin_{s, \mathbf{R}, \mathbf{t}}
\sum_{n=1}^N \| \mathbf{y}_k - (s \mathbf{Rx} + \mathbf{•}mathbf{t}) \|_2 ^2
\end{equation}



\end{document}